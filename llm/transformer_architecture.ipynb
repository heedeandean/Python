{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ⭐️ Transformer Architecture\n",
        "* ⭐️ encoder: 언어 이해\n",
        "* ⭐️ decoder: 언어 생성\n",
        "* ⭐️ 병렬 연산 O: 모든 입력을 동시에 처리\n",
        "* 대부분 LLM(Large Language Model, 대규모 언어 모델)에서 사용: 딥러닝 기반\n",
        "* 구글 논문: Attention is All you need.\n",
        "* self-attention: 입력된 문장 내의 각 단어가 서로 어떤 관련이 있는지 계산.\n",
        "---\n",
        "### cf. RRN(Recurrent Neural Network, 순환신경망)\n",
        "* 입력을 순차적⭐️으로 처리. 즉 병렬 처리 X\n",
        "---"
      ],
      "metadata": {
        "id": "8-EHdGxoUx7v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1️⃣ 토큰화(tokenization): 텍스트를 적절한 단위로 잘라 숫자 ID를 부여.\n",
        "* 사전(vocabulary): 토큰과 매칭된 숫자 ID 기록.\n",
        "* ex) 한글: (자음과 모음 < 음절 < 단어) => 작은 단위 < 큰단위\n",
        "  * 큰 단위 기준으로 자른다면\n",
        "    * (-) OOV(Out Of Vocabulary, 사전에 없는 단어): 사전에 없으면 처리하지 못하는 문제.\n",
        "    * (-) 텍스트에 등장하는 단어 수만큼 토큰 ID가 필요하기 때문에 사전의 크기가 커짐.\n",
        "    * (+) 텍스트의 의미가 잘 유지됨.\n",
        "\n",
        "* ⭐️ subword(多): 등장 빈도에 따라 토큰화 단위 결정.\n",
        "  * 자주 나오는 단어는 그대로 의미 유지, 드물게 나오는 단어는 작게 나눠 사전 크기가 커지지 않도록 함.\n",
        "  * 한글의 경우 보통 음절(ex. 특수문자, 이모티콘)과 단어(ex. 유명인 이름)로 토큰화."
      ],
      "metadata": {
        "id": "C-T5cLukYcRN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 띄어쓰기 단위로 분리 (실습 편의상, 실무에서는 subword 주로 사용.)\n",
        "input_text = '나는 최근 미국 여행을 다녀왔다'\n",
        "input_text_list = input_text.split()\n",
        "print(input_text_list)"
      ],
      "metadata": {
        "id": "em8jvF-wXhRh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29c0dc3e-6d58-449e-c6a7-c35f3aff7587"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['나는', '최근', '미국', '여행을', '다녀왔다']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 토큰 딕셔너리\n",
        "str2idx = {word: idx for idx, word in enumerate(input_text_list)}\n",
        "print(str2idx)"
      ],
      "metadata": {
        "id": "DzeVWB-VcCEa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84e8f9e8-2d88-4e14-ce35-206b43ab8205"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'나는': 0, '최근': 1, '미국': 2, '여행을': 3, '다녀왔다': 4}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "idx2str = {idx: word for idx, word in enumerate(input_text_list)}\n",
        "print(idx2str)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bkHeUMiuAdXM",
        "outputId": "8a0279c0-ffc2-4477-861a-3661710a8665"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{0: '나는', 1: '최근', 2: '미국', 3: '여행을', 4: '다녀왔다'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids = [str2idx[word] for word in input_text_list]\n",
        "print(input_ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "go9h3YUqAuny",
        "outputId": "1e1d58c3-e9d5-406f-9bc7-c50ad9b4f876"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 1, 2, 3, 4]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2️⃣ 토큰 embedding: 데이터 -> vector(숫자 집합) 변환 (의미가 담김)\n"
      ],
      "metadata": {
        "id": "_YglzsZIDVQE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# 토큰 ID 1개 => 16차원의 벡터로 변환.\n",
        "embedding_dim = 16\n",
        "embed_layer = nn.Embedding(len(str2idx), embedding_dim) # 임베딩 층: 임의의 숫자 집합으로 변환(의미 X), 실무에선 이 층도 학습시켜서 의미를 담음.\n",
        "print(embed_layer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sJmz84Y1A61q",
        "outputId": "871e8bae-eca6-4abb-a577-f0539c02ef0a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding(5, 16)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "token_embeddings = embed_layer(torch.tensor(input_ids))\n",
        "print(token_embeddings)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PLEX3EPCE8jQ",
        "outputId": "6e877d1b-c8e9-4a90-a972-2917b887d118"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.8746,  0.8480,  0.1426,  0.9157,  0.5889,  0.4193, -0.2948, -0.0175,\n",
            "          1.8022, -0.2903, -1.3834,  0.1363,  0.7212,  0.2491, -1.6416,  1.5300],\n",
            "        [ 0.5908, -2.9484,  2.0463,  1.2299, -0.5393,  0.4363,  0.3705, -0.4934,\n",
            "          0.3782, -0.2599,  0.5239, -0.7498,  0.4881,  0.8958,  0.2389,  1.6908],\n",
            "        [-1.5745, -0.6454, -0.5513,  2.2043, -0.6901,  1.1149,  0.8552,  0.1968,\n",
            "         -1.2397,  0.3358, -0.3429,  0.1870,  0.3817, -0.2721, -0.0683,  0.2225],\n",
            "        [ 0.0929,  1.2460,  1.2944, -0.8192,  1.1034,  0.4892,  0.7170,  0.3485,\n",
            "          1.6312,  1.6057,  0.6529,  0.2096,  0.9904, -0.8546, -0.1395, -0.2887],\n",
            "        [ 0.2570,  0.1427, -0.5313,  0.3440, -0.5842, -1.4011, -0.0353,  0.3135,\n",
            "          0.2477,  0.8600, -0.2627,  1.2153,  0.0806, -2.5216,  1.1992, -0.2977]],\n",
            "       grad_fn=<EmbeddingBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "token_embeddings = token_embeddings.unsqueeze(0)\n",
        "print(token_embeddings)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CQxAtsc7FOk-",
        "outputId": "3a61027d-c339-42b9-ad7d-46b55fe1a9cc"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[ 0.8746,  0.8480,  0.1426,  0.9157,  0.5889,  0.4193, -0.2948,\n",
            "          -0.0175,  1.8022, -0.2903, -1.3834,  0.1363,  0.7212,  0.2491,\n",
            "          -1.6416,  1.5300],\n",
            "         [ 0.5908, -2.9484,  2.0463,  1.2299, -0.5393,  0.4363,  0.3705,\n",
            "          -0.4934,  0.3782, -0.2599,  0.5239, -0.7498,  0.4881,  0.8958,\n",
            "           0.2389,  1.6908],\n",
            "         [-1.5745, -0.6454, -0.5513,  2.2043, -0.6901,  1.1149,  0.8552,\n",
            "           0.1968, -1.2397,  0.3358, -0.3429,  0.1870,  0.3817, -0.2721,\n",
            "          -0.0683,  0.2225],\n",
            "         [ 0.0929,  1.2460,  1.2944, -0.8192,  1.1034,  0.4892,  0.7170,\n",
            "           0.3485,  1.6312,  1.6057,  0.6529,  0.2096,  0.9904, -0.8546,\n",
            "          -0.1395, -0.2887],\n",
            "         [ 0.2570,  0.1427, -0.5313,  0.3440, -0.5842, -1.4011, -0.0353,\n",
            "           0.3135,  0.2477,  0.8600, -0.2627,  1.2153,  0.0806, -2.5216,\n",
            "           1.1992, -0.2977]]], grad_fn=<UnsqueezeBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "token_embeddings.shape # 문장 1개, 토큰 5개(각 임베딩 16차원)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sAs_vpA9F5RW",
        "outputId": "ba1c8e4c-0d24-4aaf-ecaa-95b6f1e3e68b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 5, 16])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3️⃣ 위치 인코딩(position encoding)\n",
        "* 텍스트에서 순서는 매우 중요한 정보"
      ],
      "metadata": {
        "id": "2PoYq4LCL02V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 절대적(absolute) 위치 인코딩: 토큰의 위치에 따라 고정된 임베딩을 더함. (<-> 상대적(relative) 위치 인코딩)\n",
        "max_position = 12\n",
        "position_embed_layer = nn.Embedding(max_position, embedding_dim) # 위치 인코딩 층\n",
        "print(position_embed_layer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yu5om3jcL6E6",
        "outputId": "466f311f-8359-4a3e-c520-9125cac7d032"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding(12, 16)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "position_ids = torch.arange(len(input_ids), dtype=torch.long).unsqueeze(0)\n",
        "print(position_ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ObVvzAi8Mq47",
        "outputId": "d93ef360-b944-4302-f531-42c17f659ac6"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0, 1, 2, 3, 4]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "position_encodings = position_embed_layer(position_ids)\n",
        "print(position_encodings)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zddnyewDNsFr",
        "outputId": "5298e8d1-a41f-4995-9239-3ff12947f5cb"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[ 4.4439e-01,  9.2950e-01,  1.0380e-01, -1.4422e-01, -1.7577e-01,\n",
            "           6.5715e-01, -1.6286e+00, -2.0863e+00,  4.1216e-01, -1.9550e+00,\n",
            "           3.1952e-01, -3.0065e-01,  7.5882e-01,  7.2005e-01, -1.0612e+00,\n",
            "          -4.9976e-01],\n",
            "         [-3.8469e-01,  3.0756e+00,  1.1635e+00,  9.0442e-01, -6.0577e-02,\n",
            "          -1.4860e+00, -1.5409e+00,  5.5352e-01,  1.8478e+00,  1.4109e-01,\n",
            "          -5.1490e-01,  4.2376e-01,  9.3735e-01, -2.9982e-01, -2.6732e-01,\n",
            "           1.1366e+00],\n",
            "         [-8.4598e-01,  1.1128e-01,  9.1669e-01, -8.8846e-01, -2.5481e-02,\n",
            "           8.6478e-02,  6.9501e-01,  1.4295e+00, -1.3840e-01, -8.9193e-02,\n",
            "           1.5702e+00, -1.9545e+00,  1.5986e+00, -1.0443e+00,  7.8566e-01,\n",
            "          -7.3278e-01],\n",
            "         [-5.1103e-01, -6.3794e-01, -7.1652e-01, -7.8443e-02,  7.2493e-03,\n",
            "          -9.5150e-01,  9.3579e-01,  1.0504e+00,  2.0793e-01, -8.1841e-01,\n",
            "          -1.1836e+00, -2.5159e-01,  2.0182e-03,  1.0341e+00, -1.2726e-01,\n",
            "          -7.3589e-01],\n",
            "         [-7.9785e-01, -3.3597e-02,  8.5845e-01,  9.5170e-01, -1.3763e+00,\n",
            "          -1.4445e-01, -1.8285e+00, -1.3347e+00, -2.9292e-01,  8.4520e-01,\n",
            "           2.8331e-01,  1.6613e+00, -8.6235e-01,  1.9355e+00, -5.9022e-01,\n",
            "          -1.5769e+00]]], grad_fn=<EmbeddingBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_embeddings = token_embeddings + position_encodings\n",
        "print(input_embeddings) # 모델에 입력할 최종 임베딩"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bdS-Wu8SORnT",
        "outputId": "72791bfc-18b5-4eae-a268-47236b47bd82"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[ 1.3190,  1.7775,  0.2464,  0.7714,  0.4131,  1.0765, -1.9234,\n",
            "          -2.1037,  2.2144, -2.2453, -1.0638, -0.1643,  1.4800,  0.9692,\n",
            "          -2.7028,  1.0302],\n",
            "         [ 0.2061,  0.1272,  3.2098,  2.1344, -0.5999, -1.0497, -1.1704,\n",
            "           0.0601,  2.2260, -0.1188,  0.0090, -0.3260,  1.4254,  0.5960,\n",
            "          -0.0284,  2.8274],\n",
            "         [-2.4205, -0.5341,  0.3654,  1.3158, -0.7156,  1.2014,  1.5502,\n",
            "           1.6263, -1.3781,  0.2466,  1.2272, -1.7675,  1.9803, -1.3164,\n",
            "           0.7174, -0.5103],\n",
            "         [-0.4182,  0.6081,  0.5779, -0.8976,  1.1107, -0.4623,  1.6527,\n",
            "           1.3989,  1.8391,  0.7873, -0.5306, -0.0420,  0.9924,  0.1794,\n",
            "          -0.2668, -1.0246],\n",
            "         [-0.5409,  0.1091,  0.3272,  1.2957, -1.9605, -1.5455, -1.8638,\n",
            "          -1.0212, -0.0452,  1.7052,  0.0206,  2.8766, -0.7818, -0.5861,\n",
            "           0.6090, -1.8746]]], grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_embeddings.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q9SDIH0aOlha",
        "outputId": "a5633c70-2f86-4c4c-b827-44cbfbb66b32"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 5, 16])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4️⃣ Attention: 사람이 단어 사이의 관계를 고민하는 과정을 딥러닝 모델이 수행할 수 있도록 모방.\n",
        "* 사람: 맥락을 반영해 단어를 재해석 => ⭐️ 가중치를 사용해 토큰 간 관계를 계산해서 관련이 깊은 단어와 그렇지 않은 단어를 구분\n",
        "1. query: 검색어\n",
        "2. key: 문서가 가진 특징 (ex. 제목, 저자 이름, 문장 속의 각 단어)\n",
        "3. value: 원하는 값"
      ],
      "metadata": {
        "id": "XIieXh3miPJK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "head_dim = 16\n",
        "\n",
        "weight_q = nn.Linear(embedding_dim, head_dim) # 선형 층\n",
        "weight_k = nn.Linear(embedding_dim, head_dim)\n",
        "weight_v = nn.Linear(embedding_dim, head_dim)\n",
        "\n",
        "querys = weight_q(input_embeddings)\n",
        "keys = weight_k(input_embeddings)\n",
        "values = weight_v(input_embeddings)\n",
        "\n",
        "print(querys) # (1, 5, 16)\n",
        "print(keys)\n",
        "print(values)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KzKzHYOiPc65",
        "outputId": "75ecb663-c240-4a51-dd17-56fd2d334667"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[-1.5116, -0.1596, -0.3667, -0.4219, -0.2443,  1.0163,  0.3633,\n",
            "           0.3200,  0.7242,  0.2019, -0.6352,  0.0367, -1.3659,  0.1154,\n",
            "          -0.5916, -2.3988],\n",
            "         [-0.1509,  0.5546, -0.0817, -0.3647, -0.9551,  0.3279, -1.2649,\n",
            "          -0.3024,  1.2079,  1.2180,  0.8141,  1.2654, -1.4511, -0.3375,\n",
            "           0.9175, -2.0420],\n",
            "         [ 1.1083,  0.0972,  1.0559, -0.7513, -0.1750, -1.3838, -0.5985,\n",
            "          -0.1636,  1.5050,  0.3915,  1.3903,  0.6541, -0.1344, -2.0281,\n",
            "          -0.5360,  1.2666],\n",
            "         [ 0.1711,  0.0224,  0.2384, -1.3574, -0.5296,  0.1731, -0.0779,\n",
            "          -1.2543,  0.6783, -0.1035,  0.1933,  0.0465, -0.6313, -0.3235,\n",
            "          -0.0493, -0.0162],\n",
            "         [ 0.1983,  0.2310,  0.1468, -0.5570, -0.6122, -0.6054,  0.5398,\n",
            "           0.7238, -1.7217, -0.4450, -1.1102, -0.1528,  0.4547, -0.0673,\n",
            "          -0.5439,  0.0107]]], grad_fn=<ViewBackward0>)\n",
            "tensor([[[ 0.1193,  0.0346,  1.4423, -0.1546, -0.5055,  1.1183, -0.2148,\n",
            "          -0.9557,  0.7421, -0.5483,  0.6284, -0.6941,  0.3504, -0.8726,\n",
            "           0.3129, -0.1389],\n",
            "         [ 1.9145, -0.7309,  1.9997,  0.3012, -1.5032,  0.0124, -1.4807,\n",
            "           0.2411, -1.0190,  1.2845,  0.0137, -0.1031, -0.3334, -0.3410,\n",
            "          -0.8877, -0.6966],\n",
            "         [ 0.0442, -0.0478, -0.3562, -1.0652, -0.2554, -0.4429, -0.2658,\n",
            "           1.2256, -0.6056,  0.4252,  1.0691, -0.8792, -0.3186,  1.0664,\n",
            "          -0.7953, -0.4789],\n",
            "         [ 0.1190, -1.1915,  0.3962, -0.1577, -0.7389,  0.0284, -0.1652,\n",
            "          -0.1294, -0.1925, -0.0812, -1.1455, -0.5634,  0.1575, -0.0212,\n",
            "           1.2449, -0.1209],\n",
            "         [ 0.4213,  1.8013,  1.2684,  0.5822, -0.6308, -1.6946, -1.3547,\n",
            "          -0.3156,  0.8246,  0.5867, -0.0682,  1.2524,  0.1137, -1.2724,\n",
            "          -0.5291,  1.4077]]], grad_fn=<ViewBackward0>)\n",
            "tensor([[[-1.0450,  1.8495,  0.4205,  0.9665,  0.6150,  0.0875,  1.4517,\n",
            "          -0.2343,  0.7756,  1.0752,  0.2245, -0.6812,  1.6671, -0.9566,\n",
            "          -0.1325, -0.1147],\n",
            "         [-0.6274,  1.2323,  0.0691, -0.8716, -0.1721, -0.4818,  1.5884,\n",
            "          -0.5218,  0.1242,  0.8334, -1.4875, -0.3045,  0.7453,  0.1694,\n",
            "           0.1275, -0.6092],\n",
            "         [-0.6710,  0.0349, -0.6714, -1.6507,  0.8839, -0.1471,  0.1357,\n",
            "           0.6362, -0.0144,  0.4682, -0.7534,  0.8332,  0.6781, -0.2992,\n",
            "           1.1777,  0.4068],\n",
            "         [-0.6355,  0.1032, -1.6783, -0.6814, -1.6190, -0.2025,  0.1603,\n",
            "           0.2679,  0.1061,  0.0639, -0.0109, -0.5398,  0.6015,  0.5377,\n",
            "          -0.9192,  0.1184],\n",
            "         [-0.3687, -0.2373, -0.3647,  1.0038, -0.0443, -0.8976, -1.0519,\n",
            "           1.2015, -0.5649, -0.1363, -0.0185, -1.0362, -1.3455, -0.5903,\n",
            "           0.1732,  1.0015]]], grad_fn=<ViewBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 스케일 점곱 어텐션: 1개의 어텐션 연산 수행.\n",
        "from math import sqrt\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def compute_attention(querys, keys, values, is_causal=False):\n",
        "    dim_k = querys.size(-1) # 16\n",
        "    scores = querys @ keys.transpose(-2, -1) / sqrt(dim_k)\n",
        "    if is_causal: # 디코더 - 마스크 어텐션: 작성해야 하는 텍스트를 미리 확인하게 되는 문제 해결. 즉, 미래 시점의 토큰을 제거하여 생성된 토큰까지만 확인할 수 있도록 마스크를 추가.\n",
        "        query_length = querys.size(-2)\n",
        "        key_length = keys.size(-2)\n",
        "        temp_mask = torch.ones(query_length, key_length, dtype=torch.bool).tril(diagonal=0) # 모두 1인 행렬에 대각선 아래 부분만 1로 유지되고, 나머지는 음의 무한대로 변경해 마스크를 생성.\n",
        "        scores = scores.masked_fill(temp_mask == False, float('-inf')) # 행렬의 대각선 아래 부분만 어텐션 스코어가 남고, 위쪽은 음의 무한대가 된다.\n",
        "    weights = F.softmax(scores, dim=-1) # 총 합이 1 / 음의 무한대인 대각선 윗부분은 가중치가 0이 됨.\n",
        "    return weights @ values\n",
        "\n",
        "after_attention_embeddings = compute_attention(querys, keys, values) # 입력, 출력 형태 동일\n",
        "print(after_attention_embeddings.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5M5RML23imnV",
        "outputId": "5f872bfd-c92d-45ff-c47e-536ee6ee9c1c"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 5, 16])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class AttentionHead(nn.Module):\n",
        "    def __init__(self, token_embed_dim, head_dim, is_causal=False):\n",
        "        super().__init__()\n",
        "        self.is_causal = is_causal\n",
        "        self.weight_q = nn.Linear(token_embed_dim, head_dim)\n",
        "        self.weight_k = nn.Linear(token_embed_dim, head_dim)\n",
        "        self.weight_v = nn.Linear(token_embed_dim, head_dim)\n",
        "\n",
        "    def forward(self, querys, keys, values):\n",
        "        outputs = compute_attention(\n",
        "            self.weight_q(querys),\n",
        "            self.weight_k(keys),\n",
        "            self.weight_v(values),\n",
        "            is_causal=self.is_causal\n",
        "        )\n",
        "        return outputs\n",
        "\n",
        "attention_head = AttentionHead(embedding_dim, embedding_dim)\n",
        "after_attention_embeddings = attention_head(input_embeddings, input_embeddings, input_embeddings)\n",
        "print(after_attention_embeddings.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MgQrjLbn2CQl",
        "outputId": "35133dce-10d3-4470-bd98-279ba6e7050b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 5, 16])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 멀티 헤드 어텐션: 여러 어텐션 연산을 헤드의 수(n_head)만큼 동시에 수행, 단어 간 관계를 파악.\n",
        "class MultiheadAttention(nn.Module):\n",
        "    def __init__(self, token_embed_dim, d_model, n_head, is_causal=False):\n",
        "        super().__init__()\n",
        "        self.n_head = n_head\n",
        "        self.is_causal = is_causal\n",
        "        self.weight_q = nn.Linear(token_embed_dim, d_model)\n",
        "        self.weight_k = nn.Linear(token_embed_dim, d_model)\n",
        "        self.weight_v = nn.Linear(token_embed_dim, d_model)\n",
        "        self.concat_linear = nn.Linear(d_model, d_model)\n",
        "\n",
        "    def forward(self, querys, keys, values):\n",
        "        B, T, C = querys.size()\n",
        "\n",
        "        querys = self.weight_q(querys).view(B, T, self.n_head, C // self.n_head).transpose(1, 2)\n",
        "        keys = self.weight_k(keys).view(B, T, self.n_head, C // self.n_head).transpose(1, 2)\n",
        "        values = self.weight_v(values).view(B, T, self.n_head, C // self.n_head).transpose(1, 2)\n",
        "\n",
        "        attention = compute_attention(querys, keys, values, is_causal=self.is_causal) # n_head번의 스케일 점곱 어텐션\n",
        "        output = attention.transpose(1, 2).contiguous().view(B, T, C) # 어텐션 결과를 연결\n",
        "        output = self.concat_linear(output) # 마지막 선형 층\n",
        "        return output\n",
        "\n",
        "n_head = 4\n",
        "mh_attention = MultiheadAttention(embedding_dim, embedding_dim, n_head)\n",
        "after_attention_embeddings = mh_attention(input_embeddings, input_embeddings, input_embeddings)\n",
        "print(after_attention_embeddings.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3bd6f7bd-58c7-439e-c47b-09413bc0cb3c",
        "id": "8PynPxbR6YrA"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 5, 16])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5️⃣ 정규화(normalization): 딥러닝 모델의 모든 입력 변수가 비슷한 범위와 분포를 갖도록 조정하면 각 입력 변수의 중요성을 공정하게 반영하여 더 정확한 예측을 할 수 있음.\n",
        "* 1. 층(layer) 정규화\n",
        "    - 자연어 처리\n",
        "    - Transformer Architecture\n",
        "    - 층과 층 사이에 정규화\n",
        "    - 각 토큰 임베딩의 평균과 표준편차를 구함.\n",
        "    - 사전 정규화(pre-norm)多: 먼저 층 정규화를 적용하고 어텐션과 피드 포워드 층을 통과했을 때 학습이 더 안정적. (cf. 사후 정규화(post-norm))\n",
        "\n",
        "* 2. batch 정규화: 이미지 처리"
      ],
      "metadata": {
        "id": "Q22aLSWZ7dvj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 층 정규화, 사전 정규화\n",
        "norm = nn.LayerNorm(embedding_dim) # 층 정규화 레이어\n",
        "norm_x = norm(input_embeddings) # 정규화된 임베딩\n",
        "norm_x.shape"
      ],
      "metadata": {
        "id": "KsEHlku24y3t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5ead1a5-bd2a-4737-c623-1e5867b48d8d"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 5, 16])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "norm_x.mean(dim=-1).data, norm_x.std(dim=-1).data # 평균, 표준편차"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-fBWvw49Be6R",
        "outputId": "99da3e5f-046b-4781-902d-d5dcd032bfe4"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[ 2.6077e-08, -6.7055e-08, -2.2352e-08, -3.7253e-09, -1.4901e-08]]),\n",
              " tensor([[1.0328, 1.0328, 1.0328, 1.0328, 1.0328]]))"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# feed forward layer, 완전 연결 층(fully connected layer)\n",
        "# > 입력 텍스트 전체를 이해.\n",
        "# > 데이터의 특징을 학습.\n",
        "class PreLayerNormFeedForward(nn.Module):\n",
        "    def __init__(self, d_model, dim_feedforward, dropout):\n",
        "        super().__init__()\n",
        "        self.linear1 = nn.Linear(d_model, dim_feedforward) # 선형 층\n",
        "        self.linear2 = nn.Linear(dim_feedforward, d_model) # 선형 층\n",
        "        self.dropout1 = nn.Dropout(dropout)\n",
        "        self.dropout2 = nn.Dropout(dropout)\n",
        "        self.activation = nn.GELU()\n",
        "        self.norm = nn.LayerNorm(d_model) # 층 정규화\n",
        "\n",
        "    def forward(self, src):\n",
        "        x = self.norm(src)\n",
        "        x = x + self.linear2(self.dropout1(self.activation(self.linear1(x))))\n",
        "        x = self.dropout2(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "sSSvOWSRBgDq"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6️⃣ 인코더"
      ],
      "metadata": {
        "id": "jtfXVAa4Z-v6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerEncoderLayer(nn.Module):\n",
        "    def __init__(self, d_model, n_head, dim_feedforward, dropout):\n",
        "        super().__init__()\n",
        "        self.attn = MultiheadAttention(d_model, d_model, n_head)\n",
        "        self.norm1 = nn.LayerNorm(d_model) # 층 정규화\n",
        "        self.dropout1 = nn.Dropout(dropout)\n",
        "        self.feed_forward = PreLayerNormFeedForward(d_model, dim_feedforward, dropout)\n",
        "\n",
        "    def forward(self, src):\n",
        "        norm_x = self.norm1(src)\n",
        "        attn_output = self.attn(norm_x, norm_x, norm_x)\n",
        "        x = src + self.dropout1(attn_output) # 잔차 연결(residual connection): 안정적인 학습이 가능하도록 도와줌.\n",
        "        return self.feed_forward(x)\n",
        "\n",
        "\n",
        "import copy\n",
        "def get_clones(module, N):\n",
        "    return nn.ModuleList([copy.deepcopy(module) for i in range(N)]) # 깊은 복사\n",
        "\n",
        "class TransformerEncoder(nn.Module): # 인코더 층을 N번 반복 수행.\n",
        "    def __init__(self, encoder_layer, num_layers):\n",
        "        super().__init__()\n",
        "        self.layers = get_clones(encoder_layer, num_layers)\n",
        "        self.num_layers = num_layers\n",
        "        self.norm = norm\n",
        "\n",
        "    def forward(self, src):\n",
        "        output = src\n",
        "        for mod in self.layers:\n",
        "            output = mod(output)\n",
        "        return output\n",
        ""
      ],
      "metadata": {
        "id": "OYVMtaW-Z93E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7️⃣ 디코더\n",
        "* 사람이 글을 쓸 때 앞 단어부터 순차적으로 작성하는 것처럼 트랜스포머 모델도 앞에서 생성한 토큰을 기반으로 다음 토큰을 생성.\n",
        "> 순차적으로 생성: 인과적(causal) == 자기 회귀적(auto-regressive)"
      ],
      "metadata": {
        "id": "AwrGlhh9Z9hx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerDecoderLayer(nn.Module):\n",
        "    def __init__(self, d_model, nhead, dim_feedforward=2048, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.self_attn = MultiheadAttention(d_model, d_model, nhead)\n",
        "        self.multihead_attn = MultiheadAttention(d_model, d_model, nhead)\n",
        "        self.feed_forward = PreLayerNormFeedForward(d_model, dim_feedforward, dropout)\n",
        "\n",
        "        self.norm1 = nn.LayerNorm(d_model)\n",
        "        self.norm2 = nn.LayerNorm(d_model)\n",
        "        self.dropout1 = nn.Dropout(dropout)\n",
        "        self.dropout2 = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, tgt, encoder_output, is_causal=True):\n",
        "        x = self.norm1(tgt)\n",
        "        x = x + self.dropout1(self.self_attn(x, x, x, is_causal=is_causal))\n",
        "\n",
        "        # ⭐️cross attention: 인코더의 결과를 디코더가 활용\n",
        "        x = self.norm2(x)\n",
        "        x = x + self.dropout2(self.multihead_attn(x, encoder_output, encoder_output))\n",
        "\n",
        "        return self.feed_forward(x)\n",
        "\n",
        "\n",
        "class TransformerDecoder(nn.Module):\n",
        "    def __init__(self, decoder_layer, num_layers):\n",
        "        super().__init__()\n",
        "        self.layers = get_clones(decoder_layer, num_layers) # 디코더 층을 N번 반복.\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "    def forward(self, tgt, src):\n",
        "        output = tgt\n",
        "        for mod in self.layers:\n",
        "            output = mod(output, src)\n",
        "        return output"
      ],
      "metadata": {
        "id": "3zBMTmFKjKJO"
      },
      "execution_count": 25,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMzjjZs1t569/zvjKd/Q7Si"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}